{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "08e8ccf1-5dbd-43dc-8de1-f6acf2aa1c01",
   "metadata": {},
   "source": [
    "# Spark Data Analysis\n",
    "\n",
    "This tutorial walks you through a basic data anlaysis using Spark in Camber. We will do the following:\n",
    "1. Load the Titanic dataset, hosted on Camber's Open Stash, which you have access to by default.\n",
    "2. Use Spark functionalties to transform, aggregate said dataset"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "4c1a8817-2493-4d4c-859b-021c0108d9da",
   "metadata": {},
   "source": [
    "## Loading the dataset\n",
    "First, `import camber`. We are also importing the functions module from `pyspark.sql` because it's needed for the following analysis."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "8cce3ed6-50e3-41d0-8fde-aea1b02d79d9",
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "import camber\n",
    "from pyspark.sql import functions as sf"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "6aa99245-881b-4e1c-82cd-7c488bc4abb4",
   "metadata": {},
   "source": [
    "You can create a Spark session hassle free using the `camber.spark.connect` method. Specify the `engine_size`, and Camber will provision a Spark cluster to you."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "224eebc1-bb5b-4507-9c71-c6ccbeb5a475",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Spark initialized! Remember to stop the spark session when done: spark.stop()\n"
     ]
    }
   ],
   "source": [
    "spark = camber.spark.connect(engine_size=\"XSMALL\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "7af3a628-aebe-4ec1-81a2-03ebce5fa93f",
   "metadata": {},
   "source": [
    "The Open Stash is accessed through `camber.stash`, and you can use it to load a dataset into a Spark DataFrame."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "77d08ddd-3618-49b3-a4c9-0429f8de6753",
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "titanic = camber.stash.open_stash.read_spark(\"datasets/tutorial/titanic.csv\", spark, format=\"csv\", header=True)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "ad6caadd-9d39-4216-a306-a0a5f8b52789",
   "metadata": {},
   "source": [
    "With the DataFrame loaded, let's print its schema first."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "7de1cbcd-bf83-45f8-b9b3-f8b9e9dfa5cd",
   "metadata": {
    "tags": []
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "root\n",
      " |-- PassengerId: string (nullable = true)\n",
      " |-- Survived: string (nullable = true)\n",
      " |-- Pclass: string (nullable = true)\n",
      " |-- Name: string (nullable = true)\n",
      " |-- Sex: string (nullable = true)\n",
      " |-- Age: string (nullable = true)\n",
      " |-- SibSp: string (nullable = true)\n",
      " |-- Parch: string (nullable = true)\n",
      " |-- Ticket: string (nullable = true)\n",
      " |-- Fare: string (nullable = true)\n",
      " |-- Cabin: string (nullable = true)\n",
      " |-- Embarked: string (nullable = true)\n",
      "\n"
     ]
    }
   ],
   "source": [
    "titanic.printSchema()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "af82111b-1ad7-4744-a63a-3df39c33fde8",
   "metadata": {},
   "source": [
    "We can also get a sample view of the DataFrame. Disabling the `truncate` option prints the full output for every column instead of trucating ones that are too long."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "c3062f42-ce51-4f07-abbc-6ad7605ef230",
   "metadata": {
    "tags": []
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "+-----------+--------+------+---------------------------------------------------+------+----+-----+-----+----------------+-------+-----+--------+\n",
      "|PassengerId|Survived|Pclass|Name                                               |Sex   |Age |SibSp|Parch|Ticket          |Fare   |Cabin|Embarked|\n",
      "+-----------+--------+------+---------------------------------------------------+------+----+-----+-----+----------------+-------+-----+--------+\n",
      "|1          |0       |3     |Braund, Mr. Owen Harris                            |male  |22  |1    |0    |A/5 21171       |7.25   |null |S       |\n",
      "|2          |1       |1     |Cumings, Mrs. John Bradley (Florence Briggs Thayer)|female|38  |1    |0    |PC 17599        |71.2833|C85  |C       |\n",
      "|3          |1       |3     |Heikkinen, Miss Laina                              |female|26  |0    |0    |STON/O2. 3101282|7.925  |null |S       |\n",
      "|4          |1       |1     |Futrelle, Mrs. Jacques Heath (Lily May Peel)       |female|35  |1    |0    |113803          |53.1   |C123 |S       |\n",
      "|5          |0       |3     |Allen, Mr. William Henry                           |male  |35  |0    |0    |373450          |8.05   |null |S       |\n",
      "|6          |0       |3     |Moran, Mr. James                                   |male  |null|0    |0    |330877          |8.4583 |null |Q       |\n",
      "|7          |0       |1     |McCarthy, Mr. Timothy J                            |male  |54  |0    |0    |17463           |51.8625|E46  |S       |\n",
      "|8          |0       |3     |Palsson, Master Gosta Leonard                      |male  |2   |3    |1    |349909          |21.075 |null |S       |\n",
      "|9          |1       |3     |Johnson, Mrs. Oscar W (Elisabeth Vilhelmina Berg)  |female|27  |0    |2    |347742          |11.1333|null |S       |\n",
      "|10         |1       |2     |Nasser, Mrs. Nicholas (Adele Achem)                |female|14  |1    |0    |237736          |30.0708|null |C       |\n",
      "+-----------+--------+------+---------------------------------------------------+------+----+-----+-----+----------------+-------+-----+--------+\n",
      "only showing top 10 rows\n",
      "\n"
     ]
    }
   ],
   "source": [
    "titanic.show(10, truncate=False) "
   ]
  },
  {
   "cell_type": "markdown",
   "id": "1076cd3e-2346-4d88-b2b0-a13d3b1d7d50",
   "metadata": {},
   "source": [
    "Access columns in the DataFrame in one of the following ways. The rest of the tutorial uses all these methods to show what's possible."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "id": "cb0bea20-bb3d-4a90-aed0-8d3fece08cc8",
   "metadata": {
    "tags": []
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "+-----------+-----------+-----------+\n",
      "|PassengerId|PassengerId|PassengerId|\n",
      "+-----------+-----------+-----------+\n",
      "|          1|          1|          1|\n",
      "|          2|          2|          2|\n",
      "|          3|          3|          3|\n",
      "|          4|          4|          4|\n",
      "|          5|          5|          5|\n",
      "+-----------+-----------+-----------+\n",
      "only showing top 5 rows\n",
      "\n"
     ]
    }
   ],
   "source": [
    "titanic.select(\"PassengerId\", titanic.PassengerId, sf.col(\"PassengerId\")).show(5)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "de6cc6f9-1f09-413b-a9f4-ada1a51a7051",
   "metadata": {},
   "source": [
    "## Analyzing the dataset\n",
    "\n",
    "Find the distinct values of the `Embarked` column, and then order the output in ascending order."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "id": "52c1b057-00d4-4148-9993-6a493a3df10a",
   "metadata": {
    "tags": []
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "+--------+\n",
      "|Embarked|\n",
      "+--------+\n",
      "|    null|\n",
      "|       C|\n",
      "|       Q|\n",
      "|       S|\n",
      "+--------+\n",
      "\n"
     ]
    }
   ],
   "source": [
    "titanic.select(titanic.Embarked).distinct().orderBy(titanic.Embarked).show()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "3a04c7d3-5cf1-43e6-adfb-df0925f789bd",
   "metadata": {},
   "source": [
    "Notice how we are making extensive use of `DataFrame.show()` so far. This is because Spark executes lazily. You can find more info on it [here](https://medium.com/@roshmitadey/pyspark-transformations-v-s-actions-797fc8ad16ea). A rough idea is that certain methods create the execution graph, while others force the execution. Let's filter for all survived passengers."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "id": "63692d33-e3a1-4fee-8ac6-ddc5848a6454",
   "metadata": {
    "tags": []
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "+-----------+--------+------+--------------------+------+---+-----+-----+----------------+-------+-----+--------+\n",
      "|PassengerId|Survived|Pclass|                Name|   Sex|Age|SibSp|Parch|          Ticket|   Fare|Cabin|Embarked|\n",
      "+-----------+--------+------+--------------------+------+---+-----+-----+----------------+-------+-----+--------+\n",
      "|          2|       1|     1|Cumings, Mrs. Joh...|female| 38|    1|    0|        PC 17599|71.2833|  C85|       C|\n",
      "|          3|       1|     3|Heikkinen, Miss L...|female| 26|    0|    0|STON/O2. 3101282|  7.925| null|       S|\n",
      "|          4|       1|     1|Futrelle, Mrs. Ja...|female| 35|    1|    0|          113803|   53.1| C123|       S|\n",
      "|          9|       1|     3|Johnson, Mrs. Osc...|female| 27|    0|    2|          347742|11.1333| null|       S|\n",
      "|         10|       1|     2|Nasser, Mrs. Nich...|female| 14|    1|    0|          237736|30.0708| null|       C|\n",
      "+-----------+--------+------+--------------------+------+---+-----+-----+----------------+-------+-----+--------+\n",
      "only showing top 5 rows\n",
      "\n"
     ]
    }
   ],
   "source": [
    "survivors = titanic.filter(sf.col(\"Survived\") == \"1\")\n",
    "survivors.show(5)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "585a29e7-c915-48df-a6d7-c66a3b957c75",
   "metadata": {},
   "source": [
    "Now let's count the number of passengers in each `Pclass` (passenger class)."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "id": "c051d5a1-d9cd-4875-b7eb-2ea8f38a1955",
   "metadata": {
    "tags": []
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "+------+------+\n",
      "|Pclass|Pcount|\n",
      "+------+------+\n",
      "|     1|   216|\n",
      "|     2|   184|\n",
      "|     3|   491|\n",
      "+------+------+\n",
      "\n"
     ]
    }
   ],
   "source": [
    "classes = titanic.groupBy(\"Pclass\").agg(sf.count(\"*\").alias(\"Pcount\")).orderBy(\"Pclass\")\n",
    "classes.show()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "5efaea95-c7e5-4ac3-8e68-89edb9d27b05",
   "metadata": {},
   "source": [
    "Wit the two DataFrames created, we can gain insights into survival rates by passenger class by joining them together on the values of Pclass (passenger class)."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "id": "b4cbb1f1-dccf-4f25-b3f6-76e43392d8f4",
   "metadata": {
    "tags": []
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "+------+------------+\n",
      "|Pclass|survivalRate|\n",
      "+------+------------+\n",
      "|     1|       62.96|\n",
      "|     2|       47.28|\n",
      "|     3|       24.24|\n",
      "+------+------------+\n",
      "\n"
     ]
    }
   ],
   "source": [
    "survival_rates_by_class = survivors.groupBy(\n",
    "    sf.col(\"Pclass\"),\n",
    ").agg(\n",
    "    sf.count(\"*\").alias(\"SurvivorCount\"),\n",
    ").join(\n",
    "    classes, on=\"Pclass\",\n",
    ").select(\n",
    "    sf.col(\"Pclass\"),\n",
    "    (sf.round(sf.col(\"SurvivorCount\") / sf.col(\"Pcount\") * 100, 2)).alias(\"survivalRate\")\n",
    ").orderBy(sf.col(\"survivalRate\").desc())\n",
    "survival_rates_by_class.show()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "eac2241f-99f6-4023-bd30-c7f59e0f633e",
   "metadata": {},
   "source": [
    "Congratulations! You just ran a simple data analysis in Spark. Remember to call `spark.stop()` to kill your Spark session."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "id": "49142bb1-6bf4-4b76-b45e-eb107c0899bb",
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "spark.stop()"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "PyCamber",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.10"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
