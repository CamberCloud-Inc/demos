{
  "cells": [
    {
      "cell_type": "markdown",
      "id": "08e8ccf1-5dbd-43dc-8de1-f6acf2aa1c01",
      "metadata": {},
      "source": [
        "\n",
        "This tutorial walks you through a basic data analysis using Spark in Camber:\n",
        "1. Load the Titanic dataset hosted on the Camber Open Stash, which you have access to by default.\n",
        "2. Use Spark functionalties to transform and aggregate this dataset.\n",
        "\n",
        "## Load the dataset\n",
        "\n",
        "First, `import camber`.\n",
        "Also import the functions module from `pyspark.sql`, which is needed for the following analysis."
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "id": "8cce3ed6-50e3-41d0-8fde-aea1b02d79d9",
      "metadata": {
        "tags": []
      },
      "outputs": [],
      "source": [
        "import camber\n",
        "from pyspark.sql import functions as sf"
      ]
    },
    {
      "cell_type": "markdown",
      "id": "6aa99245-881b-4e1c-82cd-7c488bc4abb4",
      "metadata": {},
      "source": [
        "\n",
        "Create a Spark session hassle free with the `camber.spark.connect()` method.\n",
        "Camber provisions a Spark cluster to you.\n",
        "For this use case, an `XSMALL` node is enough.\n",
        "For more details on node sizing, read [Engine Attributes](https://docs.cambercloud.com/docs/reference/engine-attributes/)."
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "id": "224eebc1-bb5b-4507-9c71-c6ccbeb5a475",
      "metadata": {
        "tags": []
      },
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "Spark initialized! Remember to stop the spark session when done: spark.stop()\n"
          ]
        }
      ],
      "source": [
        "spark = camber.spark.connect(node_size=\"XSMALL\")"
      ]
    },
    {
      "cell_type": "markdown",
      "id": "7af3a628-aebe-4ec1-81a2-03ebce5fa93f",
      "metadata": {},
      "source": [
        "\n",
        "\n",
        "Access the open stash through `camber.stash`, and use it to load a dataset into a Spark DataFrame.\n",
        "\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "id": "77d08ddd-3618-49b3-a4c9-0429f8de6753",
      "metadata": {
        "tags": []
      },
      "outputs": [],
      "source": [
        "titanic = camber.stash.public.read_spark(\"datasets/tutorial/titanic.csv\", spark, format=\"csv\", header=True)"
      ]
    },
    {
      "cell_type": "markdown",
      "id": "ad6caadd-9d39-4216-a306-a0a5f8b52789",
      "metadata": {},
      "source": [
        "With the DataFrame loaded, print its schema:"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "id": "7de1cbcd-bf83-45f8-b9b3-f8b9e9dfa5cd",
      "metadata": {
        "tags": []
      },
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "root\n",
            " |-- PassengerId: string (nullable = true)\n",
            " |-- Survived: string (nullable = true)\n",
            " |-- Pclass: string (nullable = true)\n",
            " |-- Name: string (nullable = true)\n",
            " |-- Sex: string (nullable = true)\n",
            " |-- Age: string (nullable = true)\n",
            " |-- SibSp: string (nullable = true)\n",
            " |-- Parch: string (nullable = true)\n",
            " |-- Ticket: string (nullable = true)\n",
            " |-- Fare: string (nullable = true)\n",
            " |-- Cabin: string (nullable = true)\n",
            " |-- Embarked: string (nullable = true)\n",
            "\n"
          ]
        }
      ],
      "source": [
        "titanic.printSchema()"
      ]
    },
    {
      "cell_type": "markdown",
      "id": "af82111b-1ad7-4744-a63a-3df39c33fde8",
      "metadata": {},
      "source": [
        "\n",
        "\n",
        "You can also get a sample view of the DataFrame. Disable the `truncate` option to print the full output for every column (instead of trucating ones that are too long):\n",
        "\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "id": "c3062f42-ce51-4f07-abbc-6ad7605ef230",
      "metadata": {
        "tags": []
      },
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "+-----------+--------+------+---------------------------------------------------+------+----+-----+-----+----------------+-------+-----+--------+\n",
            "|PassengerId|Survived|Pclass|Name                                               |Sex   |Age |SibSp|Parch|Ticket          |Fare   |Cabin|Embarked|\n",
            "+-----------+--------+------+---------------------------------------------------+------+----+-----+-----+----------------+-------+-----+--------+\n",
            "|1          |0       |3     |Braund, Mr. Owen Harris                            |male  |22  |1    |0    |A/5 21171       |7.25   |null |S       |\n",
            "|2          |1       |1     |Cumings, Mrs. John Bradley (Florence Briggs Thayer)|female|38  |1    |0    |PC 17599        |71.2833|C85  |C       |\n",
            "|3          |1       |3     |Heikkinen, Miss Laina                              |female|26  |0    |0    |STON/O2. 3101282|7.925  |null |S       |\n",
            "|4          |1       |1     |Futrelle, Mrs. Jacques Heath (Lily May Peel)       |female|35  |1    |0    |113803          |53.1   |C123 |S       |\n",
            "|5          |0       |3     |Allen, Mr. William Henry                           |male  |35  |0    |0    |373450          |8.05   |null |S       |\n",
            "|6          |0       |3     |Moran, Mr. James                                   |male  |null|0    |0    |330877          |8.4583 |null |Q       |\n",
            "|7          |0       |1     |McCarthy, Mr. Timothy J                            |male  |54  |0    |0    |17463           |51.8625|E46  |S       |\n",
            "|8          |0       |3     |Palsson, Master Gosta Leonard                      |male  |2   |3    |1    |349909          |21.075 |null |S       |\n",
            "|9          |1       |3     |Johnson, Mrs. Oscar W (Elisabeth Vilhelmina Berg)  |female|27  |0    |2    |347742          |11.1333|null |S       |\n",
            "|10         |1       |2     |Nasser, Mrs. Nicholas (Adele Achem)                |female|14  |1    |0    |237736          |30.0708|null |C       |\n",
            "+-----------+--------+------+---------------------------------------------------+------+----+-----+-----+----------------+-------+-----+--------+\n",
            "only showing top 10 rows\n",
            "\n"
          ]
        }
      ],
      "source": [
        "titanic.show(10, truncate=False) "
      ]
    },
    {
      "cell_type": "markdown",
      "id": "1076cd3e-2346-4d88-b2b0-a13d3b1d7d50",
      "metadata": {},
      "source": [
        "Access columns in the DataFrame in one of the following ways. The rest of the tutorial uses all these methods to show what's possible."
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "id": "cb0bea20-bb3d-4a90-aed0-8d3fece08cc8",
      "metadata": {
        "tags": []
      },
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "+-----------+-----------+-----------+\n",
            "|PassengerId|PassengerId|PassengerId|\n",
            "+-----------+-----------+-----------+\n",
            "|          1|          1|          1|\n",
            "|          2|          2|          2|\n",
            "|          3|          3|          3|\n",
            "|          4|          4|          4|\n",
            "|          5|          5|          5|\n",
            "+-----------+-----------+-----------+\n",
            "only showing top 5 rows\n",
            "\n"
          ]
        }
      ],
      "source": [
        "titanic.select(\"PassengerId\", titanic.PassengerId, sf.col(\"PassengerId\")).show(5)"
      ]
    },
    {
      "cell_type": "markdown",
      "id": "de6cc6f9-1f09-413b-a9f4-ada1a51a7051",
      "metadata": {},
      "source": [
        "\n",
        "\n",
        "## Analyze the dataset\n",
        "\n",
        "Find the distinct values of the `Embarked` column, and then order the output in ascending order.\n",
        "\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "id": "52c1b057-00d4-4148-9993-6a493a3df10a",
      "metadata": {
        "tags": []
      },
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "+--------+\n",
            "|Embarked|\n",
            "+--------+\n",
            "|    null|\n",
            "|       C|\n",
            "|       Q|\n",
            "|       S|\n",
            "+--------+\n",
            "\n"
          ]
        }
      ],
      "source": [
        "titanic.select(titanic.Embarked).distinct().orderBy(titanic.Embarked).show()"
      ]
    },
    {
      "cell_type": "markdown",
      "id": "3a04c7d3-5cf1-43e6-adfb-df0925f789bd",
      "metadata": {},
      "source": [
        "\n",
        "\n",
        "Notice how this tutorial uses the `DataFrame.show()` method.\n",
        "This is because Spark executes lazily.\n",
        "A rough idea is that certain methods create the execution graph, while others force the execution. See [Transformations vs Actions](https://medium.com/@roshmitadey/pyspark-transformations-v-s-actions-797fc8ad16ea).\n",
        "\n",
        "Filter for all survived passengers:\n",
        "\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "id": "63692d33-e3a1-4fee-8ac6-ddc5848a6454",
      "metadata": {
        "tags": []
      },
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "+-----------+--------+------+--------------------+------+---+-----+-----+----------------+-------+-----+--------+\n",
            "|PassengerId|Survived|Pclass|                Name|   Sex|Age|SibSp|Parch|          Ticket|   Fare|Cabin|Embarked|\n",
            "+-----------+--------+------+--------------------+------+---+-----+-----+----------------+-------+-----+--------+\n",
            "|          2|       1|     1|Cumings, Mrs. Joh...|female| 38|    1|    0|        PC 17599|71.2833|  C85|       C|\n",
            "|          3|       1|     3|Heikkinen, Miss L...|female| 26|    0|    0|STON/O2. 3101282|  7.925| null|       S|\n",
            "|          4|       1|     1|Futrelle, Mrs. Ja...|female| 35|    1|    0|          113803|   53.1| C123|       S|\n",
            "|          9|       1|     3|Johnson, Mrs. Osc...|female| 27|    0|    2|          347742|11.1333| null|       S|\n",
            "|         10|       1|     2|Nasser, Mrs. Nich...|female| 14|    1|    0|          237736|30.0708| null|       C|\n",
            "+-----------+--------+------+--------------------+------+---+-----+-----+----------------+-------+-----+--------+\n",
            "only showing top 5 rows\n",
            "\n"
          ]
        }
      ],
      "source": [
        "survivors = titanic.filter(sf.col(\"Survived\") == \"1\")\n",
        "survivors.show(5)"
      ]
    },
    {
      "cell_type": "markdown",
      "id": "585a29e7-c915-48df-a6d7-c66a3b957c75",
      "metadata": {},
      "source": [
        "\n",
        "\n",
        "Now count the number of passengers in each `Pclass` (passenger class).\n",
        "\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "id": "c051d5a1-d9cd-4875-b7eb-2ea8f38a1955",
      "metadata": {
        "tags": []
      },
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "+------+------+\n",
            "|Pclass|Pcount|\n",
            "+------+------+\n",
            "|     1|   216|\n",
            "|     2|   184|\n",
            "|     3|   491|\n",
            "+------+------+\n",
            "\n"
          ]
        }
      ],
      "source": [
        "classes = titanic.groupBy(\"Pclass\").agg(sf.count(\"*\").alias(\"Pcount\")).orderBy(\"Pclass\")\n",
        "classes.show()"
      ]
    },
    {
      "cell_type": "markdown",
      "id": "eac2241f-99f6-4023-bd30-c7f59e0f633e",
      "metadata": {},
      "source": [
        "Congratulations! You just ran a simple data analysis in Spark. Remember to call `spark.stop()` to kill your Spark session."
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "id": "49142bb1-6bf4-4b76-b45e-eb107c0899bb",
      "metadata": {
        "tags": []
      },
      "outputs": [],
      "source": [
        "spark.stop()"
      ]
    }
  ],
  "metadata": {
    "kernelspec": {
      "display_name": "PyCamber",
      "language": "python",
      "name": "python3"
    },
    "language_info": {
      "codemirror_mode": {
        "name": "ipython",
        "version": 3
      },
      "file_extension": ".py",
      "mimetype": "text/x-python",
      "name": "python",
      "nbconvert_exporter": "python",
      "pygments_lexer": "ipython3",
      "version": "3.10.10"
    }
  },
  "nbformat": 4,
  "nbformat_minor": 5
}
