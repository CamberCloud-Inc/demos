{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "0c9e8c97",
   "metadata": {
    "tags": []
   },
   "source": [
    "## Simple jupyter notebook for plotting 2D histogram of GAIA data"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "eb08fb98",
   "metadata": {},
   "source": [
    "### Import necessary modules"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "4ee6376f",
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "import matplotlib\n",
    "import matplotlib.pyplot as plt\n",
    "import time\n",
    "import pyspark.sql.functions as F\n",
    "from pyspark.sql.types import *"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "ad62cc0b-1b41-44e2-8e7c-35444e7598f5",
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "def histogram2d(df, cond1, cond2, numbins1, numbins2, min1=None, max1=None, min2=None, max2=None):\n",
    "     \"\"\"\n",
    "     Uses `cond1` and `cond2` colunm expressions to obtain data for 2D histogram calculation. The data on\n",
    "     x axis will be binned into `numbins1` bins. The data on y axis will be binned into `numbins2` bins.\n",
    "     If `min1`, `max1`, `min2` or `max2` are not spacified, they will be calculated using an additional pass\n",
    "     through the data.\n",
    "     The method returns x, y and z 2-D numpy arrays (see numpy.mgrid) which can be used as an input to\n",
    "     `matplotlib.pcolormesh`.\n",
    "\n",
    "     :param cond1: Column expression determining the data on x axis.\n",
    "     :param cond2: Column expression determining the data on y axis.\n",
    "     :param numbins1: Number of bins for x axis.\n",
    "     :param numbins2: Number of bins for y axis.\n",
    "     :param min1: Optional minimum value for x axis data.\n",
    "     :param max1: Optional maximum value for x axis data.\n",
    "     :param min2: Optional minimum value for y axis data.\n",
    "     :param max2: Optional maximum value for y axis data.\n",
    "     :return: x, y, z 2-D numpy \"meshgrid\" arrays (see numpy.mgrid)\n",
    "     \"\"\"\n",
    "     colname1 = \"axs_hist_col1\"\n",
    "     colname2 = \"axs_hist_col2\"\n",
    "     res = df.select(cond1.alias(colname1), cond2.alias(colname2))\n",
    "\n",
    "     if min1 is None or max1 is None or min2 is None or max2 is None:\n",
    "         mm = res.select(F.min(res[colname1]).alias(\"min1\"), F.max(res[colname1]).alias(\"max1\"),\n",
    "                         F.min(res[colname2]).alias(\"min2\"), F.max(res[colname2]).alias(\"max2\")).\\\n",
    "             collect()\n",
    "         (min1, max1, min2, max2) = (mm[0][\"min1\"], mm[0][\"max1\"], mm[0][\"min2\"], mm[0][\"max2\"])\n",
    "  \n",
    "     rng1 = float(max1 - min1)\n",
    "     rng2 = float(max2 - min2)\n",
    "     step1 = rng1 / numbins1\n",
    "     step2 = rng2 / numbins2\n",
    "    \n",
    "     hist2d = res.withColumn(\"bin1\", ((res[colname1]-min1)/step1).cast(\"int\")*step1+min1) \\\n",
    "         .withColumn(\"bin2\", ((res[colname2]-min2)/step2).cast(\"int\")*step2+min2).\\\n",
    "         groupBy(\"bin1\", \"bin2\").count()\n",
    "   \n",
    "     hist2data = hist2d.orderBy(hist2d.bin1, hist2d.bin2).collect()\n",
    "     \n",
    "     bin1 = list(map(lambda row: row.bin1, hist2data))\n",
    "     bin2 = list(map(lambda row: row.bin2, hist2data))\n",
    "     vals = list(map(lambda row: row[\"count\"], hist2data))\n",
    "    \n",
    "     x, y = np.mgrid[slice(min1, max1 + step1, step1),\n",
    "                     slice(min2, max2 + step2, step2)]\n",
    "     z = np.zeros(x.shape)\n",
    "     \n",
    "     for b1, b2, v in zip(bin1, bin2, vals):\n",
    "         z[round((b1-min1)/step1)][round((b2-min2)/step2)] = v\n",
    "     return x, y, z"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "83f1200a",
   "metadata": {},
   "source": [
    "### Provision Spark Cluster"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "942fbb5d-d72b-4ad4-849a-b025bca4b286",
   "metadata": {
    "tags": []
   },
   "outputs": [
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "51d0d8f2f7eb43279974baa7642f0ad3",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Output()"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "# provision with LARGE instance\n",
    "import camber\n",
    "spark = camber.spark.connect(worker_size = 'LARGE')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "53c4d013",
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "# Read in unsorted spark source catalog and set schema\n",
    "schema = StructType([StructField('solution_id', LongType(), True),\n",
    "                     StructField('designation', StringType(), True), \n",
    "                     StructField('source_id', LongType(), True), \n",
    "                     StructField('random_index', IntegerType(), True), \n",
    "                     StructField('ref_epoch', DoubleType(), True), \n",
    "                     StructField('ra', DoubleType(), True), StructField('ra_error', DoubleType(), True), \n",
    "                     StructField('dec', DoubleType(), True), StructField('dec_error', DoubleType(), True), \n",
    "                     StructField('parallax', DoubleType(), True), StructField('parallax_error', DoubleType(), True),\n",
    "                     StructField('parallax_over_error', DoubleType(), True), StructField('pm', DoubleType(), True), \n",
    "                     StructField('pmra', DoubleType(), True), StructField('pmra_error', DoubleType(), True), \n",
    "                     StructField('pmdec', DoubleType(), True), StructField('pmdec_error', DoubleType(), True), \n",
    "                     StructField('ra_dec_corr', DoubleType(), True), StructField('ra_parallax_corr', DoubleType(), True), \n",
    "                     StructField('ra_pmra_corr', DoubleType(), True), StructField('ra_pmdec_corr', DoubleType(), True), \n",
    "                     StructField('dec_parallax_corr', DoubleType(), True), StructField('dec_pmra_corr', DoubleType(), True), \n",
    "                     StructField('dec_pmdec_corr', DoubleType(), True), StructField('parallax_pmra_corr', DoubleType(), True), \n",
    "                     StructField('parallax_pmdec_corr', DoubleType(), True), StructField('pmra_pmdec_corr', DoubleType(), True), \n",
    "                     StructField('astrometric_n_obs_al', IntegerType(), True), StructField('astrometric_n_obs_ac', IntegerType(), True), \n",
    "                     StructField('astrometric_n_good_obs_al', IntegerType(), True), StructField('astrometric_n_bad_obs_al', IntegerType(), True), \n",
    "                     StructField('astrometric_gof_al', DoubleType(), True), StructField('astrometric_chi2_al', DoubleType(), True), \n",
    "                     StructField('astrometric_excess_noise', DoubleType(), True), StructField('astrometric_excess_noise_sig', DoubleType(), True), StructField('astrometric_params_solved', IntegerType(), True), \n",
    "                     StructField('astrometric_primary_flag', BooleanType(), True), StructField('nu_eff_used_in_astrometry', DoubleType(), True), StructField('pseudocolour', DoubleType(), True), StructField('pseudocolour_error', DoubleType(), True), StructField('ra_pseudocolour_corr', DoubleType(), True), \n",
    "                     StructField('dec_pseudocolour_corr', DoubleType(), True), StructField('parallax_pseudocolour_corr', DoubleType(), True), StructField('pmra_pseudocolour_corr', DoubleType(), True), StructField('pmdec_pseudocolour_corr', DoubleType(), True), \n",
    "                     StructField('astrometric_matched_transits', IntegerType(), True), StructField('visibility_periods_used', IntegerType(), True), StructField('astrometric_sigma5d_max', DoubleType(), True), StructField('matched_transits', IntegerType(), True), StructField('new_matched_transits', IntegerType(), True), \n",
    "                     StructField('matched_transits_removed', IntegerType(), True), StructField('ipd_gof_harmonic_amplitude', DoubleType(), True), StructField('ipd_gof_harmonic_phase', DoubleType(), True), StructField('ipd_frac_multi_peak', IntegerType(), True), StructField('ipd_frac_odd_win', IntegerType(), True), \n",
    "                     StructField('ruwe', DoubleType(), True), StructField('scan_direction_strength_k1', DoubleType(), True), StructField('scan_direction_strength_k2', DoubleType(), True), StructField('scan_direction_strength_k3', DoubleType(), True), StructField('scan_direction_strength_k4', DoubleType(), True), \n",
    "                     StructField('scan_direction_mean_k1', DoubleType(), True), StructField('scan_direction_mean_k2', DoubleType(), True), StructField('scan_direction_mean_k3', DoubleType(), True), StructField('scan_direction_mean_k4', DoubleType(), True), StructField('duplicated_source', BooleanType(), True), StructField('phot_g_n_obs', IntegerType(), True), StructField('phot_g_mean_flux', DoubleType(), True), StructField('phot_g_mean_flux_error', DoubleType(), True), StructField('phot_g_mean_flux_over_error', DoubleType(), True), StructField('phot_g_mean_mag', DoubleType(), True), StructField('phot_bp_n_obs', IntegerType(), True), StructField('phot_bp_mean_flux', DoubleType(), True), StructField('phot_bp_mean_flux_error', DoubleType(), True), StructField('phot_bp_mean_flux_over_error', DoubleType(), True), StructField('phot_bp_mean_mag', DoubleType(), True), StructField('phot_rp_n_obs', IntegerType(), True), StructField('phot_rp_mean_flux', DoubleType(), True), StructField('phot_rp_mean_flux_error', DoubleType(), True), StructField('phot_rp_mean_flux_over_error', DoubleType(), True), StructField('phot_rp_mean_mag', DoubleType(), True), StructField('phot_bp_n_contaminated_transits', IntegerType(), True), StructField('phot_bp_n_blended_transits', IntegerType(), True), StructField('phot_rp_n_contaminated_transits', IntegerType(), True), StructField('phot_rp_n_blended_transits', IntegerType(), True), StructField('phot_proc_mode', IntegerType(), True), StructField('phot_bp_rp_excess_factor', DoubleType(), True), StructField('bp_rp', DoubleType(), True), StructField('bp_g', DoubleType(), True), StructField('g_rp', DoubleType(), True), StructField('dr2_radial_velocity', DoubleType(), True), StructField('dr2_radial_velocity_error', DoubleType(), True), StructField('dr2_rv_nb_transits', IntegerType(), True), StructField('dr2_rv_template_teff', DoubleType(), True), StructField('dr2_rv_template_logg', DoubleType(), True), StructField('dr2_rv_template_fe_h', DoubleType(), True), StructField('l', DoubleType(), True), StructField('b', DoubleType(), True), StructField('ecl_lon', DoubleType(), True), StructField('ecl_lat', DoubleType(), True)])\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "ee11cad9-ca99-41fc-a9b0-c6770976d26e",
   "metadata": {},
   "source": [
    "### Read in Gaia data from Cloud Storage into Spark dataframe"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "b7a8e35b-9c63-4b35-ad9d-b4698fdde51b",
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "df = spark.read.csv(\"s3a://camber-spark-bkt/shared-data/gaia/gedr3/GaiaSource_*.csv.gz\",header=True,schema=schema)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "84a219a6",
   "metadata": {
    "tags": []
   },
   "source": [
    "### Transform dataframe into 2D histogram"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "id": "dd85db4b",
   "metadata": {
    "tags": []
   },
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "ERROR:root:KeyboardInterrupt while sending command.\n",
      "Traceback (most recent call last):\n",
      "  File \"/usr/local/spark/python/lib/py4j-0.10.9.5-src.zip/py4j/java_gateway.py\", line 1038, in send_command\n",
      "    response = connection.send_command(command)\n",
      "  File \"/usr/local/spark/python/lib/py4j-0.10.9.5-src.zip/py4j/clientserver.py\", line 511, in send_command\n",
      "    answer = smart_decode(self.stream.readline()[:-1])\n",
      "  File \"/opt/conda/lib/python3.10/socket.py\", line 705, in readinto\n",
      "    return self._sock.recv_into(b)\n",
      "KeyboardInterrupt\n"
     ]
    },
    {
     "ename": "KeyboardInterrupt",
     "evalue": "",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mKeyboardInterrupt\u001b[0m                         Traceback (most recent call last)",
      "Cell \u001b[0;32mIn[6], line 1\u001b[0m\n\u001b[0;32m----> 1\u001b[0m x, y, z \u001b[38;5;241m=\u001b[39m \u001b[43mhistogram2d\u001b[49m\u001b[43m(\u001b[49m\u001b[43mdf\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mdf\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mra\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mdf\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mdec\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;241;43m1000\u001b[39;49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;241;43m1000\u001b[39;49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mmin1\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[38;5;241;43m0\u001b[39;49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mmax1\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[38;5;241;43m360\u001b[39;49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mmin2\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[38;5;241;43m-\u001b[39;49m\u001b[38;5;241;43m90\u001b[39;49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mmax2\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[38;5;241;43m90\u001b[39;49m\u001b[43m)\u001b[49m\n",
      "Cell \u001b[0;32mIn[2], line 39\u001b[0m, in \u001b[0;36mhistogram2d\u001b[0;34m(df, cond1, cond2, numbins1, numbins2, min1, max1, min2, max2)\u001b[0m\n\u001b[1;32m     33\u001b[0m step2 \u001b[38;5;241m=\u001b[39m rng2 \u001b[38;5;241m/\u001b[39m numbins2\n\u001b[1;32m     35\u001b[0m hist2d \u001b[38;5;241m=\u001b[39m res\u001b[38;5;241m.\u001b[39mwithColumn(\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mbin1\u001b[39m\u001b[38;5;124m\"\u001b[39m, ((res[colname1]\u001b[38;5;241m-\u001b[39mmin1)\u001b[38;5;241m/\u001b[39mstep1)\u001b[38;5;241m.\u001b[39mcast(\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mint\u001b[39m\u001b[38;5;124m\"\u001b[39m)\u001b[38;5;241m*\u001b[39mstep1\u001b[38;5;241m+\u001b[39mmin1) \\\n\u001b[1;32m     36\u001b[0m     \u001b[38;5;241m.\u001b[39mwithColumn(\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mbin2\u001b[39m\u001b[38;5;124m\"\u001b[39m, ((res[colname2]\u001b[38;5;241m-\u001b[39mmin2)\u001b[38;5;241m/\u001b[39mstep2)\u001b[38;5;241m.\u001b[39mcast(\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mint\u001b[39m\u001b[38;5;124m\"\u001b[39m)\u001b[38;5;241m*\u001b[39mstep2\u001b[38;5;241m+\u001b[39mmin2)\u001b[38;5;241m.\u001b[39m\\\n\u001b[1;32m     37\u001b[0m     groupBy(\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mbin1\u001b[39m\u001b[38;5;124m\"\u001b[39m, \u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mbin2\u001b[39m\u001b[38;5;124m\"\u001b[39m)\u001b[38;5;241m.\u001b[39mcount()\n\u001b[0;32m---> 39\u001b[0m hist2data \u001b[38;5;241m=\u001b[39m \u001b[43mhist2d\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43morderBy\u001b[49m\u001b[43m(\u001b[49m\u001b[43mhist2d\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mbin1\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mhist2d\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mbin2\u001b[49m\u001b[43m)\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mcollect\u001b[49m\u001b[43m(\u001b[49m\u001b[43m)\u001b[49m\n\u001b[1;32m     41\u001b[0m bin1 \u001b[38;5;241m=\u001b[39m \u001b[38;5;28mlist\u001b[39m(\u001b[38;5;28mmap\u001b[39m(\u001b[38;5;28;01mlambda\u001b[39;00m row: row\u001b[38;5;241m.\u001b[39mbin1, hist2data))\n\u001b[1;32m     42\u001b[0m bin2 \u001b[38;5;241m=\u001b[39m \u001b[38;5;28mlist\u001b[39m(\u001b[38;5;28mmap\u001b[39m(\u001b[38;5;28;01mlambda\u001b[39;00m row: row\u001b[38;5;241m.\u001b[39mbin2, hist2data))\n",
      "File \u001b[0;32m/usr/local/spark/python/pyspark/sql/dataframe.py:817\u001b[0m, in \u001b[0;36mDataFrame.collect\u001b[0;34m(self)\u001b[0m\n\u001b[1;32m    807\u001b[0m \u001b[38;5;250m\u001b[39m\u001b[38;5;124;03m\"\"\"Returns all the records as a list of :class:`Row`.\u001b[39;00m\n\u001b[1;32m    808\u001b[0m \n\u001b[1;32m    809\u001b[0m \u001b[38;5;124;03m.. versionadded:: 1.3.0\u001b[39;00m\n\u001b[0;32m   (...)\u001b[0m\n\u001b[1;32m    814\u001b[0m \u001b[38;5;124;03m[Row(age=2, name='Alice'), Row(age=5, name='Bob')]\u001b[39;00m\n\u001b[1;32m    815\u001b[0m \u001b[38;5;124;03m\"\"\"\u001b[39;00m\n\u001b[1;32m    816\u001b[0m \u001b[38;5;28;01mwith\u001b[39;00m SCCallSiteSync(\u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_sc):\n\u001b[0;32m--> 817\u001b[0m     sock_info \u001b[38;5;241m=\u001b[39m \u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43m_jdf\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mcollectToPython\u001b[49m\u001b[43m(\u001b[49m\u001b[43m)\u001b[49m\n\u001b[1;32m    818\u001b[0m \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[38;5;28mlist\u001b[39m(_load_from_socket(sock_info, BatchedSerializer(CPickleSerializer())))\n",
      "File \u001b[0;32m/usr/local/spark/python/lib/py4j-0.10.9.5-src.zip/py4j/java_gateway.py:1320\u001b[0m, in \u001b[0;36mJavaMember.__call__\u001b[0;34m(self, *args)\u001b[0m\n\u001b[1;32m   1313\u001b[0m args_command, temp_args \u001b[38;5;241m=\u001b[39m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_build_args(\u001b[38;5;241m*\u001b[39margs)\n\u001b[1;32m   1315\u001b[0m command \u001b[38;5;241m=\u001b[39m proto\u001b[38;5;241m.\u001b[39mCALL_COMMAND_NAME \u001b[38;5;241m+\u001b[39m\\\n\u001b[1;32m   1316\u001b[0m     \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mcommand_header \u001b[38;5;241m+\u001b[39m\\\n\u001b[1;32m   1317\u001b[0m     args_command \u001b[38;5;241m+\u001b[39m\\\n\u001b[1;32m   1318\u001b[0m     proto\u001b[38;5;241m.\u001b[39mEND_COMMAND_PART\n\u001b[0;32m-> 1320\u001b[0m answer \u001b[38;5;241m=\u001b[39m \u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mgateway_client\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43msend_command\u001b[49m\u001b[43m(\u001b[49m\u001b[43mcommand\u001b[49m\u001b[43m)\u001b[49m\n\u001b[1;32m   1321\u001b[0m return_value \u001b[38;5;241m=\u001b[39m get_return_value(\n\u001b[1;32m   1322\u001b[0m     answer, \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mgateway_client, \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mtarget_id, \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mname)\n\u001b[1;32m   1324\u001b[0m \u001b[38;5;28;01mfor\u001b[39;00m temp_arg \u001b[38;5;129;01min\u001b[39;00m temp_args:\n",
      "File \u001b[0;32m/usr/local/spark/python/lib/py4j-0.10.9.5-src.zip/py4j/java_gateway.py:1038\u001b[0m, in \u001b[0;36mGatewayClient.send_command\u001b[0;34m(self, command, retry, binary)\u001b[0m\n\u001b[1;32m   1036\u001b[0m connection \u001b[38;5;241m=\u001b[39m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_get_connection()\n\u001b[1;32m   1037\u001b[0m \u001b[38;5;28;01mtry\u001b[39;00m:\n\u001b[0;32m-> 1038\u001b[0m     response \u001b[38;5;241m=\u001b[39m \u001b[43mconnection\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43msend_command\u001b[49m\u001b[43m(\u001b[49m\u001b[43mcommand\u001b[49m\u001b[43m)\u001b[49m\n\u001b[1;32m   1039\u001b[0m     \u001b[38;5;28;01mif\u001b[39;00m binary:\n\u001b[1;32m   1040\u001b[0m         \u001b[38;5;28;01mreturn\u001b[39;00m response, \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_create_connection_guard(connection)\n",
      "File \u001b[0;32m/usr/local/spark/python/lib/py4j-0.10.9.5-src.zip/py4j/clientserver.py:511\u001b[0m, in \u001b[0;36mClientServerConnection.send_command\u001b[0;34m(self, command)\u001b[0m\n\u001b[1;32m    509\u001b[0m \u001b[38;5;28;01mtry\u001b[39;00m:\n\u001b[1;32m    510\u001b[0m     \u001b[38;5;28;01mwhile\u001b[39;00m \u001b[38;5;28;01mTrue\u001b[39;00m:\n\u001b[0;32m--> 511\u001b[0m         answer \u001b[38;5;241m=\u001b[39m smart_decode(\u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mstream\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mreadline\u001b[49m\u001b[43m(\u001b[49m\u001b[43m)\u001b[49m[:\u001b[38;5;241m-\u001b[39m\u001b[38;5;241m1\u001b[39m])\n\u001b[1;32m    512\u001b[0m         logger\u001b[38;5;241m.\u001b[39mdebug(\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mAnswer received: \u001b[39m\u001b[38;5;132;01m{0}\u001b[39;00m\u001b[38;5;124m\"\u001b[39m\u001b[38;5;241m.\u001b[39mformat(answer))\n\u001b[1;32m    513\u001b[0m         \u001b[38;5;66;03m# Happens when a the other end is dead. There might be an empty\u001b[39;00m\n\u001b[1;32m    514\u001b[0m         \u001b[38;5;66;03m# answer before the socket raises an error.\u001b[39;00m\n",
      "File \u001b[0;32m/opt/conda/lib/python3.10/socket.py:705\u001b[0m, in \u001b[0;36mSocketIO.readinto\u001b[0;34m(self, b)\u001b[0m\n\u001b[1;32m    703\u001b[0m \u001b[38;5;28;01mwhile\u001b[39;00m \u001b[38;5;28;01mTrue\u001b[39;00m:\n\u001b[1;32m    704\u001b[0m     \u001b[38;5;28;01mtry\u001b[39;00m:\n\u001b[0;32m--> 705\u001b[0m         \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43m_sock\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mrecv_into\u001b[49m\u001b[43m(\u001b[49m\u001b[43mb\u001b[49m\u001b[43m)\u001b[49m\n\u001b[1;32m    706\u001b[0m     \u001b[38;5;28;01mexcept\u001b[39;00m timeout:\n\u001b[1;32m    707\u001b[0m         \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_timeout_occurred \u001b[38;5;241m=\u001b[39m \u001b[38;5;28;01mTrue\u001b[39;00m\n",
      "\u001b[0;31mKeyboardInterrupt\u001b[0m: "
     ]
    }
   ],
   "source": [
    "x, y, z = histogram2d(df, df.ra, df.dec, 1000, 1000, min1=0, max1=360, min2=-90, max2=90)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "1b5515d0",
   "metadata": {},
   "source": [
    "### Plot 2D histogram of Galaxy star counts and save to file"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "c687491b",
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "plt.pcolormesh(x, y, z, norm=matplotlib.colors.LogNorm(1,1.e5), cmap='viridis')\n",
    "plt.xlabel(\"Right Ascension\")\n",
    "plt.ylabel(\"Declination\")\n",
    "plt.colorbar(label='Counts')\n",
    "plt.savefig(\"gaia_hist.png\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "2281fa81-6a23-4b3f-b4c8-0825ff429a9c",
   "metadata": {},
   "source": [
    "### Cluster Spin-down"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "id": "50bb0dc4",
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "spark.stop()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "8fd2b43d-4e19-42e7-9b4f-f253845de076",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "PyCamber",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.10"
  },
  "toc-showcode": false,
  "toc-showtags": false
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
